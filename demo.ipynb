{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc3e9937",
   "metadata": {},
   "source": [
    "# ROCCO Demonstration\n",
    "\n",
    "This notebook consists of two sections.\n",
    "1. BAM Preprocessing\n",
    "1. Running Rocco\n",
    "\n",
    "The first section walks through the BAM-->WIG pipeline to generate ROCCO conformable input from a collection of samples' BAM files.\n",
    "\n",
    "The second section provides usage examples for running ROCCO on multiple chromosomes and analyzing results.\n",
    "\n",
    "**Download Input Alignments:** To acquire the ATAC-seq alignments (human lymphoblast) used for this demo, run\n",
    "```\n",
    "xargs -L 1 curl -O -J -L < demo_files/bam_links.txt\n",
    "```\n",
    "at the command line.\n",
    "\n",
    "These files are are obtained from the [ENCODE](https://www.encodeproject.org/search/?type=Experiment&control_type%21=%2A&status=released&perturbed=false&assay_title=ATAC-seq&biosample_ontology.cell_slims=lymphoblast&audit.ERROR.category%21=extremely+low+read+depth&audit.NOT_COMPLIANT.category%21=low+FRiP+score&audit.NOT_COMPLIANT.category%21=poor+library+complexity&audit.NOT_COMPLIANT.category%21=severe+bottlenecking&audit.WARNING.category%21=moderate+library+complexity&audit.WARNING.category%21=mild+to+moderate+bottlenecking&audit.WARNING.category%21=moderate+number+of+reproducible+peaks) project."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a9b36478",
   "metadata": {},
   "source": [
    "## BAM Processing\n",
    "The downloaded alignment files have already been QC-processed with the [ENCODE ATAC-seq pipeline](https://www.encodeproject.org/atac-seq/). This particular preprocessing protocol is not required, but we assume the BAM files used as input to ROCCO have already been preprocessed according to some QC standard---duplicate removal, adapter trimming, etc.\n",
    "\n",
    "### `prep_bams.py`\n",
    "This script generates a smooth signal track for each sample's BAM file and then divides each into chromosome-specific directories `tracks_<chromosome name>`, thereby providing ROCCO conformable input.\n",
    "\n",
    "The script performs the following steps:\n",
    "1. Create local links to the BAM files (and associated `.bai` files if they exist) in the directory specified by command-line arg `-i`/`--bamdir`. If the BAM files are present in the current directory, this parameter doesn't need to be specified, and no links are created. *Optional*: if the BAM files have not yet been indexed, invoke the `--index` command-line argument to call Pysam\n",
    "1. For each BAM file, check if sorted by coordinates--if not, [Pysam](https://github.com/pysam-developers/pysam) is called for sorting.\n",
    "1. Call [PEPATAC's](https://github.com/databio/pepatac) `bamSitesToWig.py` script to generate a smooth fixed-interval signal track for each sample/replicate. Note, if this script is not already present current working directory, it will be downloaded via `wget`.\n",
    "1. Divide the replicate's signal track by chromosome and place resulting subtracks into the chromosome-specific directories `tracks_<chromosome name>`\n",
    "\n",
    "See the [flowchart](https://github.com/nolan-h-hamilton/ROCCO/blob/main/docs/bamsig_flowchart.png) for a visualization.\n",
    "\n",
    "Since the downloaded alignments have not yet been indexed, we use the script's `--index` parameter. Note that these BAM files from ENCODE have already been sorted by coordinates.\n",
    "\n",
    "Users with the necessary computational resources are encouraged to make use of the `--cores` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef44cb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bamdir': '.', 'sizes': 'hg38.sizes', 'interval_length': 50, 'cores': 4, 'index': True, 'retain': False}\n",
      "creating directory `tracks_chr1`\n",
      "creating directory `tracks_chr2`\n",
      "creating directory `tracks_chr3`\n",
      "creating directory `tracks_chr4`\n",
      "creating directory `tracks_chr5`\n",
      "creating directory `tracks_chr6`\n",
      "creating directory `tracks_chr7`\n",
      "creating directory `tracks_chr8`\n",
      "creating directory `tracks_chr9`\n",
      "creating directory `tracks_chr10`\n",
      "creating directory `tracks_chr11`\n",
      "creating directory `tracks_chr12`\n",
      "creating directory `tracks_chr13`\n",
      "creating directory `tracks_chr14`\n",
      "creating directory `tracks_chr15`\n",
      "creating directory `tracks_chr16`\n",
      "creating directory `tracks_chr17`\n",
      "creating directory `tracks_chr18`\n",
      "creating directory `tracks_chr19`\n",
      "creating directory `tracks_chr20`\n",
      "creating directory `tracks_chr21`\n",
      "creating directory `tracks_chr22`\n",
      "creating directory `tracks_chrX`\n",
      "creating directory `tracks_chrY`\n",
      "running with 4 cores\n",
      "\n",
      "\n",
      "processing: ENCFF009NCL.bam\n",
      "reading alignment file with pysam...\n",
      "[E::idx_find_and_load] Could not retrieve index file for 'ENCFF009NCL.bam'\n",
      "indexing ENCFF009NCL.bam...\n",
      "\n",
      "\n",
      "processing: ENCFF110EWQ.bam\n",
      "reading alignment file with pysam...\n",
      "[E::idx_find_and_load] Could not retrieve index file for 'ENCFF110EWQ.bam'\n",
      "indexing ENCFF110EWQ.bam...\n",
      "\n",
      "\n",
      "processing: ENCFF231YYD.bam\n",
      "reading alignment file with pysam...\n",
      "[E::idx_find_and_load] Could not retrieve index file for 'ENCFF231YYD.bam'\n",
      "indexing ENCFF231YYD.bam...\n",
      "\n",
      "\n",
      "processing: ENCFF395ZMS.bam\n",
      "reading alignment file with pysam...\n",
      "[E::idx_find_and_load] Could not retrieve index file for 'ENCFF395ZMS.bam'\n",
      "indexing ENCFF395ZMS.bam...\n",
      "\n",
      "\n",
      "processing: ENCFF495DQP.bam\n",
      "reading alignment file with pysam...\n",
      "[E::idx_find_and_load] Could not retrieve index file for 'ENCFF495DQP.bam'\n",
      "indexing ENCFF495DQP.bam...\n",
      "\n",
      "\n",
      "processing: ENCFF621AYF.bam\n",
      "reading alignment file with pysam...\n",
      "[E::idx_find_and_load] Could not retrieve index file for 'ENCFF621AYF.bam'\n",
      "indexing ENCFF621AYF.bam...\n",
      "\n",
      "\n",
      "processing: ENCFF767FGV.bam\n",
      "reading alignment file with pysam...\n",
      "[E::idx_find_and_load] Could not retrieve index file for 'ENCFF767FGV.bam'\n",
      "indexing ENCFF767FGV.bam...\n",
      "\n",
      "\n",
      "processing: ENCFF797EAL.bam\n",
      "reading alignment file with pysam...\n",
      "[E::idx_find_and_load] Could not retrieve index file for 'ENCFF797EAL.bam'\n",
      "indexing ENCFF797EAL.bam...\n",
      "\n",
      "\n",
      "processing: ENCFF801THG.bam\n",
      "reading alignment file with pysam...\n",
      "[E::idx_find_and_load] Could not retrieve index file for 'ENCFF801THG.bam'\n",
      "indexing ENCFF801THG.bam...\n",
      "\n",
      "\n",
      "processing: ENCFF948HNW.bam\n",
      "reading alignment file with pysam...\n",
      "[E::idx_find_and_load] Could not retrieve index file for 'ENCFF948HNW.bam'\n",
      "indexing ENCFF948HNW.bam...\n",
      "ENCFF009NCL.bam: running bamSitesToWig.py\n",
      "Registering input file: 'ENCFF009NCL.bam'\n",
      "Temporary files will be stored in: 'tmp_ENCFF009NCL_cuttrace_k3a0zo3f'\n",
      "Processing with 4 cores...\n",
      "Reduce step (merge files)...\n",
      "Merging 160 files into output file: 'ENCFF009NCL.bam.bw'\n",
      "Splitting bigWig file by chromosome\n",
      "ENCFF110EWQ.bam: running bamSitesToWig.py\n",
      "Registering input file: 'ENCFF110EWQ.bam'\n",
      "Temporary files will be stored in: 'tmp_ENCFF110EWQ_cuttrace_85azhy30'\n",
      "Processing with 4 cores...\n",
      "Reduce step (merge files)...\n",
      "Merging 151 files into output file: 'ENCFF110EWQ.bam.bw'\n",
      "Splitting bigWig file by chromosome\n",
      "ENCFF231YYD.bam: running bamSitesToWig.py\n",
      "Registering input file: 'ENCFF231YYD.bam'\n",
      "Temporary files will be stored in: 'tmp_ENCFF231YYD_cuttrace_guxaqbvc'\n",
      "Processing with 4 cores...\n",
      "Reduce step (merge files)...\n",
      "Merging 152 files into output file: 'ENCFF231YYD.bam.bw'\n",
      "Splitting bigWig file by chromosome\n",
      "ENCFF395ZMS.bam: running bamSitesToWig.py\n",
      "Registering input file: 'ENCFF395ZMS.bam'\n",
      "Temporary files will be stored in: 'tmp_ENCFF395ZMS_cuttrace_3fwpl93l'\n",
      "Processing with 4 cores...\n",
      "Reduce step (merge files)...\n",
      "Merging 152 files into output file: 'ENCFF395ZMS.bam.bw'\n",
      "Splitting bigWig file by chromosome\n",
      "ENCFF495DQP.bam: running bamSitesToWig.py\n",
      "Registering input file: 'ENCFF495DQP.bam'\n",
      "Temporary files will be stored in: 'tmp_ENCFF495DQP_cuttrace_9ia01zpx'\n",
      "Processing with 4 cores...\n",
      "Reduce step (merge files)...\n",
      "Merging 154 files into output file: 'ENCFF495DQP.bam.bw'\n",
      "Splitting bigWig file by chromosome\n",
      "ENCFF621AYF.bam: running bamSitesToWig.py\n",
      "Registering input file: 'ENCFF621AYF.bam'\n",
      "Temporary files will be stored in: 'tmp_ENCFF621AYF_cuttrace_fsf3vgvj'\n",
      "Processing with 4 cores...\n",
      "Reduce step (merge files)...\n",
      "Merging 145 files into output file: 'ENCFF621AYF.bam.bw'\n",
      "Splitting bigWig file by chromosome\n",
      "ENCFF767FGV.bam: running bamSitesToWig.py\n",
      "Registering input file: 'ENCFF767FGV.bam'\n",
      "Temporary files will be stored in: 'tmp_ENCFF767FGV_cuttrace_kjkas8bs'\n",
      "Processing with 4 cores...\n",
      "Reduce step (merge files)...\n",
      "Merging 157 files into output file: 'ENCFF767FGV.bam.bw'\n",
      "Splitting bigWig file by chromosome\n",
      "ENCFF797EAL.bam: running bamSitesToWig.py\n",
      "Registering input file: 'ENCFF797EAL.bam'\n",
      "Temporary files will be stored in: 'tmp_ENCFF797EAL_cuttrace_u5y59bxp'\n",
      "Processing with 4 cores...\n",
      "Reduce step (merge files)...\n",
      "Merging 155 files into output file: 'ENCFF797EAL.bam.bw'\n",
      "Splitting bigWig file by chromosome\n",
      "ENCFF801THG.bam: running bamSitesToWig.py\n",
      "Registering input file: 'ENCFF801THG.bam'\n",
      "Temporary files will be stored in: 'tmp_ENCFF801THG_cuttrace_meo7ljxq'\n",
      "Processing with 4 cores...\n",
      "Reduce step (merge files)...\n",
      "Merging 151 files into output file: 'ENCFF801THG.bam.bw'\n",
      "Splitting bigWig file by chromosome\n",
      "ENCFF948HNW.bam: running bamSitesToWig.py\n",
      "Registering input file: 'ENCFF948HNW.bam'\n",
      "Temporary files will be stored in: 'tmp_ENCFF948HNW_cuttrace_y3ivg1z5'\n",
      "Processing with 4 cores...\n",
      "Reduce step (merge files)...\n",
      "Merging 152 files into output file: 'ENCFF948HNW.bam.bw'\n",
      "Splitting bigWig file by chromosome\n"
     ]
    }
   ],
   "source": [
    "!python prep_bams.py -i . --index --cores 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e0351b5c",
   "metadata": {},
   "source": [
    "## Running ROCCO\n",
    "In this section we run ROCCO and analyze results.\n",
    "### Run on Multiple Chromosomes\n",
    "`ROCCO.py` will look for chromosome-specific parameters in the CSV file specified with the `-p` argument, in our case, `demo_files/demo_params.csv`. Since a `NULL` entry is present in each cell in this file, the genome-wide defaults will be used. To run ROCCO with chromosome-specific parameters, this file can be modified accordingly, replacing `NULL` with the desired parameter value for the corresponding chromosome in each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "606b35b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running each ROCCO_chrom.py job sequentially\n",
      "job 0: python3 /work/users/n/h/nolanh/ROCCO/ROCCO_chrom.py --chrom chr20 --wig_path tracks_chr20 --budget 0.035 --gamma 1.0 --tau 0.0 --c1 1.0 --c2 1.0 --c3 1.0 --solver ECOS --bed_format 3 --outdir . --rr_iter 50\n",
      "ROCCO_chrom: reading wig file tracks_chr20/chr20_ENCFF009NCL.bam.bw.wig\n",
      "ROCCO_chrom: reading wig file tracks_chr20/chr20_ENCFF110EWQ.bam.bw.wig\n",
      "ROCCO_chrom: reading wig file tracks_chr20/chr20_ENCFF231YYD.bam.bw.wig\n",
      "ROCCO_chrom: reading wig file tracks_chr20/chr20_ENCFF395ZMS.bam.bw.wig\n",
      "ROCCO_chrom: reading wig file tracks_chr20/chr20_ENCFF495DQP.bam.bw.wig\n",
      "ROCCO_chrom: reading wig file tracks_chr20/chr20_ENCFF621AYF.bam.bw.wig\n",
      "ROCCO_chrom: reading wig file tracks_chr20/chr20_ENCFF767FGV.bam.bw.wig\n",
      "ROCCO_chrom: reading wig file tracks_chr20/chr20_ENCFF797EAL.bam.bw.wig\n",
      "ROCCO_chrom: reading wig file tracks_chr20/chr20_ENCFF801THG.bam.bw.wig\n",
      "ROCCO_chrom: reading wig file tracks_chr20/chr20_ENCFF948HNW.bam.bw.wig\n",
      "ROCCO_chrom: writing output: ./ROCCO_out_chr20_0.035_1.0_0.0_1.0_1.0_1.0.bed\n",
      "\n",
      "job 1: python3 /work/users/n/h/nolanh/ROCCO/ROCCO_chrom.py --chrom chr21 --wig_path tracks_chr21 --budget 0.035 --gamma 1.0 --tau 0.0 --c1 1.0 --c2 1.0 --c3 1.0 --solver ECOS --bed_format 3 --outdir . --rr_iter 50\n",
      "ROCCO_chrom: reading wig file tracks_chr21/chr21_ENCFF009NCL.bam.bw.wig\n",
      "ROCCO_chrom: reading wig file tracks_chr21/chr21_ENCFF110EWQ.bam.bw.wig\n",
      "ROCCO_chrom: reading wig file tracks_chr21/chr21_ENCFF231YYD.bam.bw.wig\n",
      "ROCCO_chrom: reading wig file tracks_chr21/chr21_ENCFF395ZMS.bam.bw.wig\n",
      "ROCCO_chrom: reading wig file tracks_chr21/chr21_ENCFF495DQP.bam.bw.wig\n",
      "ROCCO_chrom: reading wig file tracks_chr21/chr21_ENCFF621AYF.bam.bw.wig\n",
      "ROCCO_chrom: reading wig file tracks_chr21/chr21_ENCFF767FGV.bam.bw.wig\n",
      "ROCCO_chrom: reading wig file tracks_chr21/chr21_ENCFF797EAL.bam.bw.wig\n",
      "ROCCO_chrom: reading wig file tracks_chr21/chr21_ENCFF801THG.bam.bw.wig\n",
      "ROCCO_chrom: reading wig file tracks_chr21/chr21_ENCFF948HNW.bam.bw.wig\n",
      "ROCCO_chrom: writing output: ./ROCCO_out_chr21_0.035_1.0_0.0_1.0_1.0_1.0.bed\n",
      "\n",
      "job 2: python3 /work/users/n/h/nolanh/ROCCO/ROCCO_chrom.py --chrom chr22 --wig_path tracks_chr22 --budget 0.035 --gamma 1.0 --tau 0.0 --c1 1.0 --c2 1.0 --c3 1.0 --solver ECOS --bed_format 3 --outdir . --rr_iter 50\n",
      "ROCCO_chrom: reading wig file tracks_chr22/chr22_ENCFF009NCL.bam.bw.wig\n",
      "ROCCO_chrom: reading wig file tracks_chr22/chr22_ENCFF110EWQ.bam.bw.wig\n",
      "ROCCO_chrom: reading wig file tracks_chr22/chr22_ENCFF231YYD.bam.bw.wig\n",
      "ROCCO_chrom: reading wig file tracks_chr22/chr22_ENCFF395ZMS.bam.bw.wig\n",
      "ROCCO_chrom: reading wig file tracks_chr22/chr22_ENCFF495DQP.bam.bw.wig\n",
      "ROCCO_chrom: reading wig file tracks_chr22/chr22_ENCFF621AYF.bam.bw.wig\n",
      "ROCCO_chrom: reading wig file tracks_chr22/chr22_ENCFF767FGV.bam.bw.wig\n",
      "ROCCO_chrom: reading wig file tracks_chr22/chr22_ENCFF797EAL.bam.bw.wig\n",
      "ROCCO_chrom: reading wig file tracks_chr22/chr22_ENCFF801THG.bam.bw.wig\n",
      "ROCCO_chrom: reading wig file tracks_chr22/chr22_ENCFF948HNW.bam.bw.wig\n",
      "ROCCO_chrom: writing output: ./ROCCO_out_chr22_0.035_1.0_0.0_1.0_1.0_1.0.bed\n",
      "\n",
      "combining output files --> ROCCO_out_combined.bed\n"
     ]
    }
   ],
   "source": [
    "!python ROCCO.py -p demo_files/demo_params.csv --combine ROCCO_out_combined.bed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f522ac0",
   "metadata": {},
   "source": [
    "### ROCCO predicted peak regions over `chr22` using default parameters\n",
    "IDR thresholded peaks and fold change signals from ENCODE are included\n",
    "![Alt text](demo_files/demo1.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9545e2ed",
   "metadata": {},
   "source": [
    "### ROCCO predicted peak regions over a random 5mb region in `chr22`\n",
    "![Alt text](demo_files/demo2.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cceebde0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
